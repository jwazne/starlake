# Tutorial

Load and validate, in one shot or incrementally, JSON, XML and CSV files into your datawarehouse using different write strategies.

## Prerequisites

If you skipped the extract step above, you can download the data from [here](https://github.com/starlake-ai/starlake/tree/master/samples/starbake/incoming/starbake).
and copy them to the incoming/starbake folder.
The folder contains now three files:
- product.xml
- order_20240228.json
- order_line_20240228.csv

## Infer schema
This is done by running the following command:

```bash
starlake infer-schema --input-path incoming/starbake --clean
```

Your metadata `load` folder should now contain the folder `starbake` with following files:
- products.sl.yml
- orders.sl.yml
- order_lines.yml
- _config.sl.yml

The ìnfer-schema` command has created a schema file for each of the files in the incoming folder trying to detect the schema of the files.
These schema files are used to load the data into the datawarehouse.

In a real life scenario, you may want to review the schema files and adjust them to your needs.

## Stage before loading
starlake can stage the files before loading them into the datawarehouse.
This is useful when your files arrive in a different folder from the one where they are loaded into the datawarehouse.

To move the incoming files to the stage folder. Run the following command:

```bash
starlake stage
```


## Load data into your datawarehouse

Run the following command to load the files in the incoming folder.
Since we are target the DuckDB datawarehouse, we need to set the SL_ENV variable to `DUCKDB` to activate the env.DUCKDB.sl.yml configuration file.

```bash

SL_ENV=DUCKDB starlake load

```

## Query your loaded files in your datawarehouse
That's it you have loaded the data into your datawarehouse and just need to query it.
To query your database, you can use the following command:

```bash
$ cd $SL_ROOT
$ duckdb datasets/duckdb.db
v0.10.0 20b1486d11
Enter ".help" for usage hints.
D show;
┌──────────┬──────────┬─────────────────┬──────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────┬───────────┐
│ database │  schema  │      name       │     column_names     │                                           column_types                                            │ temporary │
│ varchar  │ varchar  │     varchar     │      varchar[]       │                                             varchar[]                                             │  boolean  │
├──────────┼──────────┼─────────────────┼──────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┤
│ duckdb   │ audit    │ audit           │ [JOBID, PATHS, DOM…  │ [VARCHAR, VARCHAR, VARCHAR, VARCHAR, BOOLEAN, BIGINT, BIGINT, BIGINT, TIMESTAMP, INTEGER, VARCH…  │ false     │
│ duckdb   │ audit    │ rejected        │ [JOBID, TIMESTAMP,…  │ [VARCHAR, TIMESTAMP, VARCHAR, VARCHAR, VARCHAR, VARCHAR]                                          │ false     │
│ duckdb   │ starbake │ order           │ [customer_id, orde…  │ [BIGINT, BIGINT, VARCHAR, TIMESTAMP]                                                              │ false     │
│ duckdb   │ starbake │ order_line      │ [order_id, product…  │ [BIGINT, BIGINT, BIGINT, DOUBLE]                                                                  │ false     │
│ duckdb   │ starbake │ product         │ [category, cost, d…  │ [VARCHAR, DOUBLE, VARCHAR, VARCHAR, DOUBLE, BIGINT]                                               │ false     │
└──────────┴──────────┴─────────────────┴──────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────┴───────────┘

D select * from starbake.order limit 5;
┌─────────────┬──────────┬───────────┬─────────────────────────┐
│ customer_id │ order_id │  status   │        timestamp        │
│    int64    │  int64   │  varchar  │        timestamp        │
├─────────────┼──────────┼───────────┼─────────────────────────┤
│           6 │        1 │ Cancelled │ 2024-02-05 22:19:15.454 │
│          23 │        2 │ Delivered │ 2024-01-02 11:44:37.59  │
│          20 │        3 │ Delivered │ 2024-02-10 23:10:30.685 │
│           6 │        4 │ Delivered │ 2024-01-17 19:31:22.917 │
│          17 │        5 │ Pending   │ 2024-01-19 01:26:06.674 │
└─────────────┴──────────┴───────────┴─────────────────────────┘

D .quit
$
```

Our raw files have been loaded into the datawarehouse and we can now start to [transform our data to build insights](../transform/tutorial).

