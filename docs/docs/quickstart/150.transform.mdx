---
sidebar_position: 150
title: Transform
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Now that our file is successfully loaded and available as a table, we usually need to create KPIs or specialized tables.
To illustrate how transform may be defined on tables, we will create two tables, one containing customers living in France
and another one containing customers living in the USA.


## Templated Job
Starlake Transforms support Jinja2 templating inside SQL requests.

We create a file `metadata/transform/kpi/bycountry.sql` with the following content

```SQL
select * from sales.customers where lower(country) like lower('{{ p_country }}')
```

By creating the sql file in the kpi folder, we instruct Starlake to put the result of the query in a schema (dataset in BigQuery)
named 'kpi'.
The french customers will be stored in the table `cust_france` and the american customers in the table `cust_usa`.
SQL file alone is not sufficient to be a Starlake Transform.

Since y default the table is named after the SQL file name, ```bycountry.sql``` will create a table named ```bycountry```.
We need to configure a dynamic table name based on the country name in the YAML configuration file.
Therefore we need to create the YAML file `metadata/transform/kpi/_config.comet.yml`.
This file will instruct where the result of the SQL request will be stored.

```yaml
transform:
  tasks:
    - name: bycountry # We define the name of the transform.
      table: cust_{{ p_country }} # We define the table name based on the country name.
      write: OVERWRITE # We overwrite the table each time the job is executed.

```

<Tabs groupId="customers">
<TabItem value="france" label="French customers table">

```sh
$ cd $HOME/myproject
$ $HOME/starlake/starlake.sh transform --name kpi.bycountry --options p_country=France
```

</TabItem>
<TabItem value="usa" label="American customers table">

```sh
$ cd $HOME/myproject
$ $HOME/starlake/starlake.sh transform --name kpi.bycountry --options p_country=USA
```

</TabItem>
</Tabs>

The `--options` allow to define variables that will be used for substitution and thus allowing a query to be parameterized.


:::note
The `--options` parameter is optional. If not provided,
the transform will be executed with the default values defined in the env.{{SL_ENV}}.comet.yml  file.
:::


## Targeting another datawarehouse


<Tabs groupId="warehouses">
<TabItem value="bq" label="BigQuery">

```yaml
transform:
  name: bycountry
  tasks:
    - table: cust_{{ p_country }}
      write: OVERWRITE
      connectionRef: BigQuery
```
</TabItem>
<TabItem value="databricks" label="Databricks">

```yaml
transform:
  tasks:
    - domain: business
      table: cust_{{ p_country }}
      write: OVERWRITE
      connectionRef: DATABRICKS
```

</TabItem>
<TabItem value="hive" label="Hive">

```yaml
transform:
  engine: Spark
  tasks:
    - domain: business
      table: cust_{{ p_country }}
      write: OVERWRITE
      connectionRef: DATABRICKS
```

</TabItem>
<TabItem value="redshift" label="Redshift">

Amazon Redshift uses a JDBC URL and a specific format. We need to define our redshift connection in the metadata/application.comet.yml file as follows:

```yaml
connections:
  Redshift:
    format: "com.databricks.spark.redshift"
    options:
      url: "jdbc:redshift://redshifthost:5439/database",
      user: "username",
      password: "pass",
      tempdir: "s3n://path/for/temp/data",
      aws_iam_role: "arn:aws:iam::123456789000:role/redshift_iam_role"
```

```yaml
transform:
  name: bycountry_{{ p_country }}
  engine: Redshift
  tasks:
    - domain: business
      table: cust_{{ p_country }}
      write: OVERWRITE
      sink:
        type: Redshift
```

</TabItem>
<TabItem value="snowflake" label="Snowflake">

Snowflake uses a JDBC URL and a specific format. We need to define our snowflake connection in the metadata/application.comet.yml file as follows:

```yaml

connections:
  Snowflake:
    format = "net.snowflake.spark.snowflake"
    options:
      url: "jdbc:snowflake://myorganization-myaccount.snowflakecomputing.com/",
      user: "username",
      password: "pass",
      account: "myorganization-myaccount",
      warehouse: "mywh",
      autopushdown: "off" # to pushdown set to 'on'
      db: "mydb",
      schema: "public"

```

```yaml
transform:
  name: bycountry
  engine: Snowflake
  tasks:
    - table: cust_{{ p_country }}
      write: OVERWRITE
      connectionRef: Snowflake
```

</TabItem>

</Tabs>
