---
sidebar_position: 300
---

# Transform

Once your data is ingested, you may start to expose insights by joining them and / or create meaningful aggregates.

In the example below, we join the `sellers` and `orders` tables to compute the total amount sold by each seller.

We want to do it on parquet files and on BigQuery. We need to create 2 env files, one per environment.

## Parquet Job

Create the `env.FS.comet.yml` file in the `metadata` folder as follows:

```yaml
env:
  myConnectionRef: "LocalFileSystem"
```

Create in teh folder `metadata/transform/kpi/` the SQL file that describe the job and name it `sellers_kpi.comet.yml`:

```SQL
select seller_email, sum(amount) as sum from sellers, orders where sellers.id = orders.seller_id group by sellers.seller_email
```

Before executing the job, we set the `SL_ENV` variable to `FS` to make sure variables are instantiated correctly:

````shell
export SL_ENV=FS
$ starlake.sh transform --name kpi.sellers_kpi
````

## BigQuery Job
To execute the same request on BigQuery,  create the `env.BQ.comet.yml` file in the `metadata` folder as follows:

```yaml
env:
  myConnectionRef: "bigquery"
```

Before executing the job, we set the `SL_ENV` variable to `BQ` to make sure variables are instantiated correctly:

````shell
export SL_ENV=BQ
$ starlake.sh transform --name kpi.sellers_kpi
````

