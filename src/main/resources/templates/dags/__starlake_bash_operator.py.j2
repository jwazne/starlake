{% include 'templates/dags/__starlake_operator.py.j2' %}
from airflow.operators.bash import BashOperator

from airflow.datasets import Dataset

class AirflowStarlakeBashJob(AirflowStarlakeJob):
    """Airflow Starlake Bash Job."""
    def __init__(self, pre_load_strategy: StarlakePreLoadStrategy|str=None, options: dict=None, **kwargs):
        super().__init__(pre_load_strategy=pre_load_strategy, options=options, **kwargs)

    def sl_job(self, task_id: str, arguments: list, **kwargs) -> BaseOperator:
        """Overrides AirflowStarlakeJob.sl_job()"""
        command = get_context_var("SL_STARLAKE_PATH", "starlake", self.options) + f" {' '.join(arguments)}"
        kwargs.update({'pool': kwargs.get('pool', self.pool)})
        return BashOperator(
            task_id=task_id,
            bash_command=command,
            cwd=self.sl_root,
            **kwargs
        )

sl_operator = AirflowStarlakeBashJob(options=options)
