{% include 'templates/dags/__starlake_operator.py.j2' %}
from airflow.operators.bash import BashOperator

from airflow.datasets import Dataset

class StarlakeBashOperator(IStarlakeOperator):
    """Starlake Bash Operator."""
    def __init__(self, pre_load_strategy: StarlakePreLoadStrategy|str=None, options: dict=options, **kwargs):
        super().__init__(pre_load_strategy=pre_load_strategy, options=options, **kwargs)

    def sl_job(self, task_id: str, arguments: list, **kwargs) -> BaseOperator:
        """Overrides IStarlakeOperator.sl_job()"""
        command = get_context_var("SL_STARLAKE_PATH", "starlake", self.options) + f" {' '.join(arguments)}"
        kwargs.update({'pool': kwargs.get('pool', DEFAULT_POOL)})
        return BashOperator(
            task_id=task_id,
            bash_command=command,
            cwd=SL_ROOT,
            **kwargs
        )

sl_operator = StarlakeBashOperator()
